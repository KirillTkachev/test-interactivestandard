{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16a860ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "sys.path.append('../src/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6b0b17",
   "metadata": {},
   "source": [
    "Посмотрим на скачанные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3389692",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_CSV = \"../data/raw/test-task/clusters.csv\"                  \n",
    "CLEANED_CSV = \"../data/processed/clusters_cleaned.csv\"\n",
    "RAW_IMAGES = \"../data/raw/test-task/clusters/\"\n",
    "CLEANED_IMAGES = \"../data/processed/cleaned_clusters/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1cc1b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1521, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>f75f7082d62a44e7bfd373532877c9a6</td>\n",
       "      <td>70d7af617866428ba9d49a77505b8de0.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>f75f7082d62a44e7bfd373532877c9a6</td>\n",
       "      <td>075eb928960e46e0ae058f3e3e2efd4f.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>f75f7082d62a44e7bfd373532877c9a6</td>\n",
       "      <td>81f97e936ce84a5fa1ccabff3ad75725.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>f75f7082d62a44e7bfd373532877c9a6</td>\n",
       "      <td>3cbe3279c96848aa8bf24cb54e9de861.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>f75f7082d62a44e7bfd373532877c9a6</td>\n",
       "      <td>376ba3f5dfc44bfa90a4d72df1d5000f.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                        cluster_id  \\\n",
       "0           0  f75f7082d62a44e7bfd373532877c9a6   \n",
       "1           1  f75f7082d62a44e7bfd373532877c9a6   \n",
       "2           2  f75f7082d62a44e7bfd373532877c9a6   \n",
       "3           3  f75f7082d62a44e7bfd373532877c9a6   \n",
       "4           4  f75f7082d62a44e7bfd373532877c9a6   \n",
       "\n",
       "                              file_name  \n",
       "0  70d7af617866428ba9d49a77505b8de0.jpg  \n",
       "1  075eb928960e46e0ae058f3e3e2efd4f.jpg  \n",
       "2  81f97e936ce84a5fa1ccabff3ad75725.jpg  \n",
       "3  3cbe3279c96848aa8bf24cb54e9de861.jpg  \n",
       "4  376ba3f5dfc44bfa90a4d72df1d5000f.jpg  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.read_csv(RAW_CSV)\n",
    "print(dataframe.shape)\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ec789ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.drop(columns=dataframe.columns[0], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cd7d49",
   "metadata": {},
   "source": [
    "В какой-то момент я осознал, что все изображения без лиц имеют одинаковое разрешение - (1080, 1920). Почистим датасет от них"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "362f6c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_ids = []\n",
    "\n",
    "for path in os.listdir(RAW_IMAGES):\n",
    "    full_path = RAW_IMAGES + '/' + path\n",
    "    image = Image.open(full_path)\n",
    "    if image.size != (1920, 1080) and image.size != (1080, 1920):\n",
    "        true_ids.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46b04b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(557, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f75f7082d62a44e7bfd373532877c9a6</td>\n",
       "      <td>70d7af617866428ba9d49a77505b8de0.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f75f7082d62a44e7bfd373532877c9a6</td>\n",
       "      <td>075eb928960e46e0ae058f3e3e2efd4f.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f75f7082d62a44e7bfd373532877c9a6</td>\n",
       "      <td>81f97e936ce84a5fa1ccabff3ad75725.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f75f7082d62a44e7bfd373532877c9a6</td>\n",
       "      <td>3cbe3279c96848aa8bf24cb54e9de861.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f75f7082d62a44e7bfd373532877c9a6</td>\n",
       "      <td>376ba3f5dfc44bfa90a4d72df1d5000f.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         cluster_id                             file_name\n",
       "0  f75f7082d62a44e7bfd373532877c9a6  70d7af617866428ba9d49a77505b8de0.jpg\n",
       "1  f75f7082d62a44e7bfd373532877c9a6  075eb928960e46e0ae058f3e3e2efd4f.jpg\n",
       "2  f75f7082d62a44e7bfd373532877c9a6  81f97e936ce84a5fa1ccabff3ad75725.jpg\n",
       "3  f75f7082d62a44e7bfd373532877c9a6  3cbe3279c96848aa8bf24cb54e9de861.jpg\n",
       "4  f75f7082d62a44e7bfd373532877c9a6  376ba3f5dfc44bfa90a4d72df1d5000f.jpg"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_dataframe = dataframe[dataframe['file_name'].isin(true_ids)] \n",
    "print(cleaned_dataframe.shape)\n",
    "cleaned_dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd63365",
   "metadata": {},
   "source": [
    "Дальше построим ембеддинги для изображений и уже их будем кластеризовать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c18e8236",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kirill/Documents/test-interactive-standard/.venv/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import features.cluster_builder as cluster_builder\n",
    "import features.embeddings_builder as embeddings_builder\n",
    "import entities\n",
    "from utils.utils import (\n",
    "    evaluate_model,\n",
    "    create_target_dataframe\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1714bf34",
   "metadata": {},
   "source": [
    "Заведем параметры для CLIP и кластеризации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "668b332e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_params = entities.embedding_params.EmbeddingParams(input_data_path=\"../data/processed/cleaned_clusters/\", output_path=\"../models/embeddings.npy\", \n",
    "                         clip_model=\"openai/clip-vit-large-patch14-336\", device=\"cuda:0\", allowed_extensions=[\".jpg\"], batch_size=32,\n",
    "                          rebuild_embeddings=True)\n",
    "\n",
    "clustering_params = entities.clustering_params.ClusteringParams(embeddings_path=\"../models/embeddings.npy\", annoy_index_metric=\"angular\", \n",
    "                                                               annoy_index_trees=100, linkage_method=\"complete\", fcluster_criterion=\"distance\",\n",
    "                                                               fcluster_threshold=0.62)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18c84e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
      "Generating CLIP embeddings: 100%|██████████| 557/557 [01:48<00:00,  5.13it/s]\n"
     ]
    }
   ],
   "source": [
    "embeddings_builder_ = embeddings_builder.EmbeddingsBuilder(embedding_params)\n",
    "embeddings_builder_.build_embeddings()\n",
    "images_to_pathes, all_images_ids = embeddings_builder_.get_images_to_paths()\n",
    "\n",
    "cluster_builder_ = cluster_builder.ClusterBuilder(clustering_params)\n",
    "labels, image_ids_clusters = cluster_builder_.build_image_clusters(all_images_ids)\n",
    "\n",
    "cleaned_dataframe = pd.read_csv(\"../data/processed/clusters_cleaned.csv\")\n",
    "metrics = evaluate_model(cleaned_dataframe, create_target_dataframe(labels, images_to_pathes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f3de929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'homogenity_score': 0.9671600270041537, 'completeness_score': 0.9214733343408211, 'v_measure_score': 0.9437640922428762}\n"
     ]
    }
   ],
   "source": [
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba0ae54",
   "metadata": {},
   "source": [
    "Вроде, получается неплохо"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
